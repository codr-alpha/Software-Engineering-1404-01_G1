Based on the provided SDD, SRS, and existing codebase structure, here is a detailed 3-Sprint Jira plan.

**Project Context:** You are building the **Team 7 Microservice** (TOEFL Writing & Speaking Assessment) within a larger Django project (`app404`).
**Tech Stack:** Django, PostgreSQL, HTML/CSS/JS (Templates), Docker.

---

### **Sprint 1: Core Architecture & Writing Assessment**
**Goal:** Implement the database schema, basic API structure, and the full "Writing" assessment flow.

#### **Mahan Zavari (Back-End & AI)**
**Task 1: Database Schema Implementation**
*   **Description:** Translate the ER Diagram from the SDD into Django Models in `team7/models.py`.
*   **Subtasks:**
    *   Create `Question` model (fields: prompt_text, task_type, mode, etc.).
    *   Create `Evaluation` model (FK to User, scores, submitted_text).
    *   Create `DetailedScore` model (FK to Evaluation, criterion, score_value).
    *   Run `makemigrations` and ensure clean migration files.

**Task 2: Writing Evaluation Service Logic**
*   **Description:** Implement the business logic for analyzing text using the `EvaluationService` and `WritingEvaluator` classes defined in the SDD.
*   **Subtasks:**
    *   Create `services.py` in `team7`.
    *   Implement `validateLength(text)` logic.
    *   Create the LLM Client stub (mock response first, then connect to API).
    *   Implement `evaluateWriting(text)` to parse LLM JSON response.

**Task 3: Writing API Endpoints**
*   **Description:** Create the API views to handle writing submissions.
*   **Subtasks:**
    *   Update `team7/urls.py` with `submit-writing`.
    *   Implement `submit_writing` view in `team7/views.py` (accept JSON).
    *   Connect the View to the `EvaluationService`.
    *   Return standardized JSON response (as per SRS Appendix B).

#### **Amin Rezaeeyan (Front-End)**
**Task 4: Writing Interface UI**
*   **Description:** Create the Writing Task HTML page based on Figma designs.
*   **Subtasks:**
    *   Create `team7/templates/team7/writing.html`.
    *   Style the text area and "Submit" button using variables from `common.css`.
    *   Implement the "Question Prompt" display area.

**Task 5: AJAX Submission Logic**
*   **Description:** Handle the form submission via JavaScript to avoid page reloads.
*   **Subtasks:**
    *   Create `team7/static/team7/js/writing.js`.
    *   Write `fetch()` logic to POST data to `/team7/api/submit-writing/`.
    *   Handle loading states (spinner) while waiting for AI response.
    *   Handle error responses (e.g., text too short).

#### **Mohammad Yarahmadi (Full-Stack/QA)**
**Task 6: Infrastructure & Docker Setup**
*   **Description:** Ensure Team 7's container runs correctly within the main project.
*   **Subtasks:**
    *   Review `team7/Dockerfile` and `team7/docker-compose.yml`.
    *   Ensure database persistence settings in `settings.py` for Team 7 are correct.
    *   Verify `gateway.conf` routing for `/team7/`.

**Task 7: API Validation & Unit Tests (Writing)**
*   **Description:** Write tests to ensure the Writing API behaves as expected (SRS requirements).
*   **Subtasks:**
    *   Update `team7/tests.py`.
    *   Test input validation (min 50 words, max 1000 words).
    *   Test auth protection (ensure only logged-in users can submit).
    *   Test database saving (ensure `Evaluation` is created after submit).

---

### **Sprint 2: Speaking Assessment & Advanced AI**
**Goal:** Implement the Speaking assessment flow, Audio handling, and integration with ASR (Speech-to-Text).

#### **Mahan Zavari (Back-End & AI)**
**Task 8: ASR Service Integration**
*   **Description:** Implement the Speech-to-Text logic in the backend.
*   **Subtasks:**
    *   Update `services.py` to include `SpeakingEvaluator`.
    *   Implement `transcribe_audio(file)` using an external API (e.g., OpenAI Whisper).
    *   Handle API timeouts and errors.

**Task 9: Speaking Evaluation Logic**
*   **Description:** Connect the transcribed text to the LLM for scoring.
*   **Subtasks:**
    *   Construct the LLM Prompt for Speaking (include nuances like "Delivery", "Topic Development").
    *   Implement `evaluateSpeaking(audio_file)` in the Service layer.
    *   Save audio file path and transcript to the Database.

**Task 10: Speaking API Endpoint**
*   **Description:** Handle `multipart/form-data` uploads for audio.
*   **Subtasks:**
    *   Create `submit-speaking` endpoint.
    *   Handle file upload in Django (`request.FILES`).
    *   Validate audio file type (.wav, .mp3) and size limit (10MB).

#### **Amin Rezaeeyan (Front-End)**
**Task 11: Audio Recorder Component**
*   **Description:** Build a JS recorder to capture microphone input.
*   **Subtasks:**
    *   Implement `MediaRecorder` API in `team7/static/team7/js/recorder.js`.
    *   Create UI controls: Record, Stop, Playback, Reset.
    *   Visualize recording status (e.g., timer or wave animation).

**Task 12: Speaking Result Visualization**
*   **Description:** Display the complex JSON result from Speaking analysis.
*   **Subtasks:**
    *   Design the Result Modal/Section in HTML.
    *   Parse the JSON response to show "Transcript" and "AI Feedback".
    *   Show scores for Pronunciation/Grammar visually (e.g., progress bars).

#### **Mohammad Yarahmadi (Full-Stack/QA)**
**Task 13: File Storage Strategy**
*   **Description:** Manage how audio files are stored (Local vs S3).
*   **Subtasks:**
    *   Configure `MEDIA_ROOT` and `MEDIA_URL` specifically for Team 7.
    *   Ensure uploaded files have unique names (UUID).
    *   Implement a cleanup script (or logic) to delete temp files if processing fails.

**Task 14: Integration Tests (Speaking)**
*   **Description:** End-to-end testing of the speaking flow.
*   **Subtasks:**
    *   Create test cases with dummy audio files.
    *   Mock the ASR and LLM external calls in `tests.py` to save costs/time during testing.
    *   Verify JSON response structure matches the Frontend expectations.

---

### **Sprint 3: Analytics, Dashboard & Polish**
**Goal:** Implement the "My Progress" dashboard, Admin features, and final system hardening.

#### **Mahan Zavari (Back-End & AI)**
**Task 15: Analytics Service**
*   **Description:** Backend logic to calculate user progress.
*   **Subtasks:**
    *   Implement `getHistory(user_id)` query.
    *   Implement `calculateTrend(scores)` logic (e.g., moving average).
    *   Create `api/history/` endpoint.

**Task 16: Admin API & Monitoring**
*   **Description:** Endpoints for the Admin panel (system health).
*   **Subtasks:**
    *   Create `api_logs` model recording logic (middleware or decorator).
    *   Create `api/admin/health` endpoint (check DB connection, External API status).

#### **Amin Rezaeeyan (Front-End)**
**Task 17: Dashboard UI (Chart.js)**
*   **Description:** Visualize the user's progress over time.
*   **Subtasks:**
    *   Integrate a charting library (e.g., Chart.js) into `index.html`.
    *   Fetch data from `api/history/` on page load.
    *   Render "Writing" vs "Speaking" score trends.

**Task 18: Error Handling & Empty States**
*   **Description:** Polish the UI for edge cases.
*   **Subtasks:**
    *   Design "No History Found" state.
    *   Design "Server Error" / "API Timeout" friendly messages.
    *   Ensure mobile responsiveness of the dashboard.

#### **Mohammad Yarahmadi (Full-Stack/QA)**
**Task 19: Performance & Load Testing**
*   **Description:** Ensure the system meets NFRs (Response time).
*   **Subtasks:**
    *   Use a tool (like Locust or Apache Bench) to simulate concurrent users.
    *   Measure response time of the LLM/ASR endpoints.
    *   Optimize DB queries (add indexes to `user_id` and `created_at`).

**Task 20: Final QA & Documentation**
*   **Description:** Final verification before release.
*   **Subtasks:**
    *   Run full regression test suite.
    *   Verify all "TODO" comments in code are resolved.
    *   Update `README.md` with instructions on how to set up API Keys for AI services.