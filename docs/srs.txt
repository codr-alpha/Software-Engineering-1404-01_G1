Based on the comprehensive documentation provided across **PDF 1 (Diagrams)**, **PDF 2 (Software Design Document - SDD)**, and the newly added **PDF 3 (Software Requirements Specification - SRS)**, here is the fully integrated Technical Specification for the TOEFL AI Evaluation Platform.

This document links the *requirements* (What needs to be done) with the *architecture* (How it is built) and the *visuals* (How it flows).

---

# Integrated Technical Specification: TOEFL AI Evaluation Microservice

## 1. System Overview & Scope
**Type:** Independent, Containerized Microservice.
**Tech Stack:** Python 3.9+, Docker, Linux Environment.
**Deployment:** Cloud-agnostic (AWS, GCP, Azure).
**Core Function:** Automated scoring and feedback for TOEFL Writing and Speaking tasks, designed to be consumed by external client platforms (e.g., Student Portals).

### Actors & Roles (from SRS & Use Case Diagram)
1.  **Student:** Submits essays/audio, receives instant feedback (<15s for writing, <25s for speaking).
2.  **Instructor:** Views student progress trends and historical performance.
3.  **Admin:** Manages API keys, monitors system health, and triggers manual model validation.

---

## 2. Architecture & Component Design
The system follows a **3-Layered Architecture** (Controller-Service-Repository) ensuring Separation of Concerns.

### A. Controller Layer (API Gateway)
*   **Protocols:** HTTPS only (Port 443), RESTful.
*   **`EvaluationController`**:
    *   **Endpoint:** Single versioned entry point (e.g., `/api/v1/evaluate`).
    *   **Requirement (FR-API-02):** Distinguishes between `writing` and `speaking` via a `mode` parameter.
    *   **Security (FR-SEC-01):** Implements protection against SQL Injection and XSS.
*   **`AuthController`**:
    *   **Mechanism:** Validates API Keys for service access (FR-API-03) and JWT for user sessions.
    *   **Error Handling:** Returns standard HTTP codes (401, 403) as defined in **Appendix B** of the SRS.

### B. Service Domain (Business Logic)
*   **`EvaluationService`**: Orchestrator for data flow.
    *   **Constraint (C-01):** Logic must strictly adhere to the latest **ETS TOEFL iBT rubrics**.
*   **`WritingEvaluator`**:
    *   **Inputs:** UTF-8 String.
    *   **Constraint (FR-WR-01):** Minimum 50 words, Maximum 1000 words.
    *   **Logic:** Scores based on Development, Organization, and Grammar/Vocabulary.
*   **`SpeakingEvaluator`**:
    *   **Inputs:** Audio files (WAV, MP3, FLAC).
    *   **Constraint (FR-SP-01):** Max 10MB file size, duration 30-90 seconds.
    *   **Logic:** Scores based on Delivery (Fluidity), Language Use, and Topic Development.
*   **`AnalyticsService`**:
    *   **Logic:** Computes trends (FR-MON-02) using metrics like Mean Absolute Error (MAE) and Quadratic Weighted Kappa (QWK) to compare AI scores against human benchmarks.

### C. Infrastructure Layer (Data & Integrations)
*   **`LLMClient` (External Interface SI-01):** Connects to Large Language Models for content analysis.
*   **`ASRClient` (External Interface SI-02):** Connects to Speech-to-Text services.
*   **`ResultRepository`:** Handles database transactions.

---

## 3. Database Design & Data Retention
**Database:** PostgreSQL (Managed Service).
**Compliance:** GDPR & CCPA (FR-EXT-02).

### Schema Refinements (from SRS Constraints)
1.  **`users`**: Stores PII. *Constraint:* Data must only be used for service delivery (Privacy).
2.  **`evaluations`**:
    *   **Retention Policy (NFR-DATA-01):** Active data kept for **2 years**. Archived/Anonymized data kept for **5 years**. Hard delete after 5 years.
    *   **Fields:** Must store `rubric_version_id` to track changes in scoring standards over time (FR-RES-02).
3.  **`api_logs`**: Used for calculating system uptime (Target: 99.5%) and response latency.

---

## 4. Detailed Functional Workflows

### Workflow 1: Writing Evaluation (UC-01 & FR-WR)
1.  **Input:** Student submits text via Client UI.
2.  **Validation:**
    *   Check: Text length 50-1000 words.
    *   Check: Task type (Integrated vs. Independent).
3.  **Processing:**
    *   System generates Prompt + Rubric.
    *   LLM analyzes text.
4.  **Output:** JSON Object containing:
    *   Overall Score (0.0 - 5.0).
    *   Sub-scores (Grammar, Organization).
    *   **Actionable Feedback:** At least one specific suggestion for improvement (FR-WR-05).
5.  **Performance Target:** Response returned in **< 15 seconds** (95th percentile).

### Workflow 2: Speaking Evaluation (UC-02 & FR-SP)
1.  **Input:** Audio recording (30-90s).
2.  **Validation:**
    *   Check: File format (WAV/MP3/FLAC) and Size (<10MB).
3.  **Processing:**
    *   **ASR Phase:** Convert audio to text.
    *   **Quality Check:** If audio is silent/noisy, return specific error message (See Appendix B).
    *   **LLM Phase:** Analyze Transcript + Prosody data (Delivery).
4.  **Output:** JSON Object containing scores and "speech-to-text" transcript.
5.  **Performance Target:** Response returned in **< 25 seconds** (95th percentile).

### Workflow 3: Admin & Monitoring (UC-04 & FR-MON)
1.  **Health Check:** `Admin` queries `/health` endpoint.
2.  **Accuracy Monitoring:**
    *   System runs weekly batch jobs comparing AI scores against a "Golden Set" of human-graded responses.
    *   **Metric:** reliability must maintain **QWK > 0.7** (NFR-REL-01).
3.  **API Management:** Admin can Revoke/Issue API keys via the Admin Panel.

---

## 5. Non-Functional Requirements (NFRs)
*   **Scalability (NFR-SCALE-01):** Horizontal scaling using Docker containers to handle load (tested up to 50 concurrent users).
*   **Availability (NFR-AVAIL-01):** 99.5% Uptime (excluding scheduled maintenance).
*   **Model Management (NFR-ORG-04):** Zero-downtime deployment for new AI model versions.
*   **Development:** Agile/Scrum methodology, Git version control with >80% unit test coverage.

## 6. API Error Handling (Appendix B)
The system must return standard HTTP codes with descriptive JSON messages:
*   **400:** `INVALID_INPUT` (Text too short/long, invalid file type).
*   **401:** `UNAUTHENTICATED` (Missing/Invalid API Key).
*   **403:** `PERMISSION_DENIED` (Valid key, but insufficient scope).
*   **429:** `RATE_LIMIT_EXCEEDED` (Too many requests).
*   **500:** `INTERNAL_ERROR` (Server-side crash).
*   **503:** `SERVICE_UNAVAILABLE` (Upstream LLM/ASR provider is down).